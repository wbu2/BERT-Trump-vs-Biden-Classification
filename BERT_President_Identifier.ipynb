{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT President Identifier.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNH5sf1nZFlGKZI5EhJqsiC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ae911930845347e7839b33fb1ae3ac38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c223f57f4e8d4f9ba26474861835129b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6639b526af2f4a84bddffbb274295719",
              "IPY_MODEL_30e8352ef998460b8b17b1d1d1531bb1"
            ]
          }
        },
        "c223f57f4e8d4f9ba26474861835129b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6639b526af2f4a84bddffbb274295719": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_43c43259436b459c92ace72ce7117238",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dbeb7e8ce1aa45a99424c0ebafef550f"
          }
        },
        "30e8352ef998460b8b17b1d1d1531bb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7d7489da51b940eb8695254763726584",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [02:30&lt;00:00, 1.54kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_732f035af4054f0cab5529121cece6e0"
          }
        },
        "43c43259436b459c92ace72ce7117238": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dbeb7e8ce1aa45a99424c0ebafef550f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7d7489da51b940eb8695254763726584": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "732f035af4054f0cab5529121cece6e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "13c96d3dbe1940149675636d7e27ba1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d177e38796d64adc8c0a4d513b851632",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4842e90c5fe949779fbd4d8fc513ae55",
              "IPY_MODEL_d24b5d787c8045e59e146ba94b52bacd"
            ]
          }
        },
        "d177e38796d64adc8c0a4d513b851632": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4842e90c5fe949779fbd4d8fc513ae55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e0c6f4ff58ec414e801e2b98f6b70653",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f8feb6734a65438c9059f512b6fbacd2"
          }
        },
        "d24b5d787c8045e59e146ba94b52bacd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cd77982d2ed14d99ab6037512b7ef419",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 959B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b6b91428412c474cbdcb00e5e8eb7a47"
          }
        },
        "e0c6f4ff58ec414e801e2b98f6b70653": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f8feb6734a65438c9059f512b6fbacd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cd77982d2ed14d99ab6037512b7ef419": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b6b91428412c474cbdcb00e5e8eb7a47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d4f917f2e33b4ceca9c0adb7f17957fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_abcdf35347e14e4f812450f51b955f35",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_aa022f5d97f440bdbeaf896a4c705f4a",
              "IPY_MODEL_d36476d899c946d8933b357e009941d5"
            ]
          }
        },
        "abcdf35347e14e4f812450f51b955f35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aa022f5d97f440bdbeaf896a4c705f4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d9e6723832044057a315752a7c11ca13",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2311f88723a74074a034272f2c5a445f"
          }
        },
        "d36476d899c946d8933b357e009941d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_36b3dad44ef6432295dd181329bf8b24",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:30&lt;00:00, 14.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c95df58840734eceb691a68df9c43218"
          }
        },
        "d9e6723832044057a315752a7c11ca13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2311f88723a74074a034272f2c5a445f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "36b3dad44ef6432295dd181329bf8b24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c95df58840734eceb691a68df9c43218": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wbu2/BERT-Trump-vs-Biden-Classification/blob/master/BERT_President_Identifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s84U22sND-9g",
        "colab_type": "text"
      },
      "source": [
        "# This BERT Model was based on [Chris McCormick's BERT Model](http://mccormickml.com/2019/07/22/BERT-fine-tuning/) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9s5NgpCGxfG",
        "colab_type": "text"
      },
      "source": [
        "# **Colab Setup**\n",
        "\n",
        " I will use a GPU to train this model.\n",
        "\n",
        " I will use the transformers package from the Hugging Face Library, a pytorch interface for using Bert.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2vhCOE-fHkx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9bcf8bbb-d222-4f42-9d7c-b746b20bbadf"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTLw9_j_gG52",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ae31c335-2f35-4b8c-ab95-2c1ad7ea7ef0"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohvqQJ6agaBK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "f31c42d2-f124-47ef-cf07-a37cb2551399"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\r\u001b[K     |▍                               | 10kB 19.0MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 2.1MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 2.8MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 2.5MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 2.7MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 3.0MB/s eta 0:00:01\r\u001b[K     |███▍                            | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |███▉                            | 92kB 3.6MB/s eta 0:00:01\r\u001b[K     |████▎                           | 102kB 3.5MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 133kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 143kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 153kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 163kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 174kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 184kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████                        | 194kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 204kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████                       | 215kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 225kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 235kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 245kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 256kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 266kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 276kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 286kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 296kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 307kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 317kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 327kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 337kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 348kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 358kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 368kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 378kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 389kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 399kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 409kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 419kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 430kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 440kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 450kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 460kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 471kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 481kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 491kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 501kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 512kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 522kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 532kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 542kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 552kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 563kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 573kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 583kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 593kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 604kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 614kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 624kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 634kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 645kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 655kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 665kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 675kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 686kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 696kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 706kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 716kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 727kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 737kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 747kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 757kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 768kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 778kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 15.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 40.1MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 38.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=efed231a63304110d651c77bb5afe8f12c88d497f459b96ac52b36c5c4c1ef5a\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2hVSCJ3H5Va",
        "colab_type": "text"
      },
      "source": [
        "# **Prepare Input**\n",
        "\n",
        "BERT requires input to be tokenized using the included tokenizer. These tokens are mapped to their index in the vocabulary from the tokenizer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7618fsdwX_bu",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "outputId": "ce4153cb-d7c5-47bf-b8af-79844d949031"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-03745dec-7485-4f8f-914e-f42e44001605\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-03745dec-7485-4f8f-914e-f42e44001605\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODPDUY9vB-zC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "75e79909-749e-475a-f98e-89f8ddf5921a"
      },
      "source": [
        "#Read in Pandas Dataframe containing raw tweets from Trump and Biden\n",
        "import pandas as pd\n",
        "import pickle\n",
        "df = pd.read_pickle('/content/bert-input.pkl')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>realDonaldTrump</th>\n",
              "      <th>JoeBiden</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The  Election will be totally rigged if Mail-I...</td>\n",
              "      <td>Women have decided the course of history with ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Because of my strong focus on the China Virus,...</td>\n",
              "      <td>Thirty years on, we still have work to do to r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Lamestream Media, including @FoxNews, whic...</td>\n",
              "      <td>Folks, we have just  days until Election Day. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>There is NO WAY a place like Pennsylvania can ...</td>\n",
              "      <td>In  days, we have the chance to set our nation...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>So the Washington Post is running the Reagan F...</td>\n",
              "      <td>days.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     realDonaldTrump                                           JoeBiden\n",
              "0  The  Election will be totally rigged if Mail-I...  Women have decided the course of history with ...\n",
              "1  Because of my strong focus on the China Virus,...  Thirty years on, we still have work to do to r...\n",
              "2  The Lamestream Media, including @FoxNews, whic...  Folks, we have just  days until Election Day. ...\n",
              "3  There is NO WAY a place like Pennsylvania can ...  In  days, we have the chance to set our nation...\n",
              "4  So the Washington Post is running the Reagan F...                                              days."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0VWwPkwG6Hv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137,
          "referenced_widgets": [
            "ae911930845347e7839b33fb1ae3ac38",
            "c223f57f4e8d4f9ba26474861835129b",
            "6639b526af2f4a84bddffbb274295719",
            "30e8352ef998460b8b17b1d1d1531bb1",
            "43c43259436b459c92ace72ce7117238",
            "dbeb7e8ce1aa45a99424c0ebafef550f",
            "7d7489da51b940eb8695254763726584",
            "732f035af4054f0cab5529121cece6e0"
          ]
        },
        "outputId": "f4c601cf-cced-45d5-ee7a-abcdece19536"
      },
      "source": [
        "#A single Trump tweet is passed into this tokenizer to show what is done to the input\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "trump_tweets = df.realDonaldTrump.values\n",
        "\n",
        "print(' Original: ', trump_tweets[0])\n",
        "\n",
        "print('Tokenized: ', tokenizer.tokenize(trump_tweets[0]))\n",
        "\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(trump_tweets[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae911930845347e7839b33fb1ae3ac38",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Original:  The  Election will be totally rigged if Mail-In Voting is allowed to take place, &amp; everyone knows it. So much time is taken talking about foreign influence, but the same people wont even discuss Mail-In election corruption. Look at Patterson, N.J. % of vote was corrupted!\n",
            "Tokenized:  ['the', 'election', 'will', 'be', 'totally', 'rigged', 'if', 'mail', '-', 'in', 'voting', 'is', 'allowed', 'to', 'take', 'place', ',', '&', 'amp', ';', 'everyone', 'knows', 'it', '.', 'so', 'much', 'time', 'is', 'taken', 'talking', 'about', 'foreign', 'influence', ',', 'but', 'the', 'same', 'people', 'won', '##t', 'even', 'discuss', 'mail', '-', 'in', 'election', 'corruption', '.', 'look', 'at', 'patterson', ',', 'n', '.', 'j', '.', '%', 'of', 'vote', 'was', 'corrupted', '!']\n",
            "Token IDs:  [1996, 2602, 2097, 2022, 6135, 25216, 2065, 5653, 1011, 1999, 6830, 2003, 3039, 2000, 2202, 2173, 1010, 1004, 23713, 1025, 3071, 4282, 2009, 1012, 2061, 2172, 2051, 2003, 2579, 3331, 2055, 3097, 3747, 1010, 2021, 1996, 2168, 2111, 2180, 2102, 2130, 6848, 5653, 1011, 1999, 2602, 7897, 1012, 2298, 2012, 12424, 1010, 1050, 1012, 1046, 1012, 1003, 1997, 3789, 2001, 27279, 999]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-AFom75K6cT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "94df3ae8-57a4-4a3d-c4cf-340caca1591b"
      },
      "source": [
        "#All tweets are tokenized\n",
        "import pickle\n",
        "t = open(\"/content/trump-list.pkl\", \"rb\")\n",
        "b = open(\"/content/joe-list.pkl\", \"rb\")\n",
        "\n",
        "trump_tweets = pickle.load(t)  \n",
        "biden_tweets = pickle.load(b)\n",
        "t.close()\n",
        "b.close()\n",
        "print(trump_tweets[-1])\n",
        "tweet_list = trump_tweets + biden_tweets\n",
        "input_ids = []\n",
        "lengths = []\n",
        "\n",
        "for tweet in tweet_list:\n",
        "  encoded_sent = tokenizer.encode(tweet, add_special_tokens = True)\n",
        "  input_ids.append(encoded_sent)\n",
        "  lengths.append(len(encoded_sent))\n",
        "\n",
        "print('Original: ', tweet_list[0])\n",
        "print('Tokenized: ', tokenizer.tokenize(tweet_list[0]))\n",
        "print('Token IDs:', input_ids[0])\n",
        "print(len(trump_tweets), \"Trump Tweets\")\n",
        "print(len(biden_tweets), \"Biden Tweets\")\n",
        "print(len(tweet_list), \"Tweets\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Newly released documents show Schiff knew all along there was no proof of Russia-Trump collusion. Wall Street Journal\n",
            "Original:  The  Election will be totally rigged if Mail-In Voting is allowed to take place, &amp; everyone knows it. So much time is taken talking about foreign influence, but the same people wont even discuss Mail-In election corruption. Look at Patterson, N.J. % of vote was corrupted!\n",
            "Tokenized:  ['the', 'election', 'will', 'be', 'totally', 'rigged', 'if', 'mail', '-', 'in', 'voting', 'is', 'allowed', 'to', 'take', 'place', ',', '&', 'amp', ';', 'everyone', 'knows', 'it', '.', 'so', 'much', 'time', 'is', 'taken', 'talking', 'about', 'foreign', 'influence', ',', 'but', 'the', 'same', 'people', 'won', '##t', 'even', 'discuss', 'mail', '-', 'in', 'election', 'corruption', '.', 'look', 'at', 'patterson', ',', 'n', '.', 'j', '.', '%', 'of', 'vote', 'was', 'corrupted', '!']\n",
            "Token IDs: [101, 1996, 2602, 2097, 2022, 6135, 25216, 2065, 5653, 1011, 1999, 6830, 2003, 3039, 2000, 2202, 2173, 1010, 1004, 23713, 1025, 3071, 4282, 2009, 1012, 2061, 2172, 2051, 2003, 2579, 3331, 2055, 3097, 3747, 1010, 2021, 1996, 2168, 2111, 2180, 2102, 2130, 6848, 5653, 1011, 1999, 2602, 7897, 1012, 2298, 2012, 12424, 1010, 1050, 1012, 1046, 1012, 1003, 1997, 3789, 2001, 27279, 999, 102]\n",
            "1045 Trump Tweets\n",
            "1076 Biden Tweets\n",
            "2121 Tweets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ITKc2eUSbeZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "bf0bfd0a-95ca-4de8-af67-b5de23c4206b"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "print('Min tweet length: ', min(lengths))\n",
        "print('Median tweet length: ', np.median(lengths))\n",
        "print('Max tweet length: ', max(lengths))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Min tweet length:  4\n",
            "Median tweet length:  43.0\n",
            "Max tweet length:  91\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qe-JMLuTvH22",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "outputId": "7b1f4fc5-5a6a-4ed5-de53-9946755d342f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set(font_scale = 1.5)\n",
        "sns.distplot(lengths, kde = False)\n",
        "plt.title(\"Tweet Lengths\")\n",
        "plt.xlabel(\"Tweet Length\")\n",
        "plt.ylabel(\"# of Tweets\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, '# of Tweets')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTAbmyxyQ_Qh",
        "colab_type": "text"
      },
      "source": [
        "Bert requires a constant input length. Since the tweets vary in length we will pad them with a token ID of 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7ZC0flYxrMN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d629f0f5-6483-4f1f-a8c3-e06b2d02ca52"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "MAX_LEN = 110\n",
        "#Pad with 0\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFoPhfrACpyO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for tweet in input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in tweet]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdN_3Y0rC1Di",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for\n",
        "# training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#first 1045 tweets are from trump and the 1076 tweets after are biden's\n",
        "labels = []\n",
        "for i in range(1045):\n",
        "  labels.append(0)\n",
        "for i in range(1076):\n",
        "  labels.append(1)\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXG-bqiJGUQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype \n",
        "# for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nU3ZR3dDGeYX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kQfix9YT62b",
        "colab_type": "text"
      },
      "source": [
        "# **Training**\n",
        "\n",
        "I will use BertForSequenceClassification which is the BERT model with a classification layer on top"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXIDM3WDGzie",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "13c96d3dbe1940149675636d7e27ba1e",
            "d177e38796d64adc8c0a4d513b851632",
            "4842e90c5fe949779fbd4d8fc513ae55",
            "d24b5d787c8045e59e146ba94b52bacd",
            "e0c6f4ff58ec414e801e2b98f6b70653",
            "f8feb6734a65438c9059f512b6fbacd2",
            "cd77982d2ed14d99ab6037512b7ef419",
            "b6b91428412c474cbdcb00e5e8eb7a47",
            "d4f917f2e33b4ceca9c0adb7f17957fa",
            "abcdf35347e14e4f812450f51b955f35",
            "aa022f5d97f440bdbeaf896a4c705f4a",
            "d36476d899c946d8933b357e009941d5",
            "d9e6723832044057a315752a7c11ca13",
            "2311f88723a74074a034272f2c5a445f",
            "36b3dad44ef6432295dd181329bf8b24",
            "c95df58840734eceb691a68df9c43218"
          ]
        },
        "outputId": "9c6e52e1-ed8d-4a15-c25a-52abf073b0dc"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13c96d3dbe1940149675636d7e27ba1e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d4f917f2e33b4ceca9c0adb7f17957fa",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piPzFInLHGRR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4NDy-EBHG4T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpxIchQJHWWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Wn7rL6dHXba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKdK9gcHIKjf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "outputId": "e900c7f6-f03b-4aad-8741-f36478c2840e"
      },
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     60.    Elapsed: 0:00:42.\n",
            "\n",
            "  Average training loss: 0.24\n",
            "  Training epcoh took: 0:01:02\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     60.    Elapsed: 0:00:41.\n",
            "\n",
            "  Average training loss: 0.06\n",
            "  Training epcoh took: 0:01:02\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     60.    Elapsed: 0:00:41.\n",
            "\n",
            "  Average training loss: 0.04\n",
            "  Training epcoh took: 0:01:02\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     60.    Elapsed: 0:00:41.\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Training epcoh took: 0:01:02\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZS64uCQ0TmRT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "9641a30a-11c0-43d1-9396-e0493a5e5d78"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIzQOWMRXa8W",
        "colab_type": "text"
      },
      "source": [
        "# **Testing**\n",
        "\n",
        "I will load test data and prepare them for input to the Bert model. To evaluate predictions, I will use Matthew's Correlation Coefficient since it is a binary classification problem. The MCC is in essence a correlation coefficient value between -1 and +1. A coefficient of +1 represents a perfect prediction, 0 an average random prediction and -1 an inverse prediction.[[source: Wikipedia]](https://en.wikipedia.org/wiki/Matthews_correlation_coefficient)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGG72buYaizs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "3012774f-ce1f-424d-991e-f331b4c4779c"
      },
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "t_test = open(\"/content/trump-test.pkl\", \"rb\")\n",
        "b_test = open(\"/content/joe-test.pkl\", \"rb\")\n",
        "\n",
        "trump_test_tweets = pickle.load(t_test)  \n",
        "biden_test_tweets = pickle.load(b_test)\n",
        "used_biden_test = biden_test_tweets[0:500]\n",
        "t.close()\n",
        "b.close()\n",
        "\n",
        "#Trump Data from 4/24/2020 to 5/12/2020\n",
        "#Biden Data from 11/19/2019 to 2/2/2020 \n",
        "print(trump_test_tweets[0])\n",
        "print(trump_test_tweets[-1])\n",
        "print(used_biden_test[0])\n",
        "print(used_biden_test[-1])\n",
        "\n",
        "test_data = trump_test_tweets + used_biden_test\n",
        "test_labels = []\n",
        "#0 is trump and 1 is biden\n",
        "for i in range (223):\n",
        "  test_labels.append(0)\n",
        "for i in range (500):\n",
        "  test_labels.append(1)\n",
        "\n",
        "print(len(test_labels))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRANSITION TO GREATNESS\n",
            "I will never let our Post Office fail. It has been mismanaged for years, especially since the advent of the internet and modern-day technology. The people that work there are great, and we’re going to keep them happy, healthy, and well!\n",
            "#TeamJoe has been hard at work making phone calls, knocking doors, and talking with as many folks as possible over the last nine months—but it all comes down to these last few days. We need all hands on deck for this final push. Sign up to volunteer today:  \n",
            "When I talk about the soul of this nation—I’m talking about a country where no one has to worry about whether they can afford health care.\n",
            "\n",
            "I fought like hell to get Obamacare passed and I’m the only one on tonight’s stage who has led a transformation of our health care system.\n",
            "723\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4ksUhWIjhVQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for tweet in test_data:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        tweet,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "\n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(test_labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIZUbnE5jRH4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "42d92dbb-c27c-496b-f88f-d2645beefe5b"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test tweets...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 723 test tweets...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgnju9ffogVr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "146ea5ea-ae5e-48c1-b6d2-b7707e326016"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  \n",
        "  # Calculate and store the coef for this batch.  \n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
        "  matthews_set.append(matthews)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaXNPxZYo3e5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2f7341e6-fe3c-4468-8e7d-3897d29f693a"
      },
      "source": [
        "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('MCC: %.3f' % mcc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MCC: 0.943\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6XxZTTXb0BD",
        "colab_type": "text"
      },
      "source": [
        "# **Conclusion**\n",
        "\n",
        "Using my trained Bert model for sequence classification, I was able to obtain a MCC of 0.943 which is near perfect. My model trained on tweets from Trump and Biden's timelines was able to accrurately predict whether a given tweet was Trump's or Biden's."
      ]
    }
  ]
}